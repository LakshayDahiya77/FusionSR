{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjR1kyDJRYCl"
      },
      "source": [
        "## Cell 1: Mount Drive & Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SinoocLsFXyX",
        "outputId": "75e8bf1c-2f65-426e-8926-5bed2f348aae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required libraries\n",
        "!pip install -q einops scikit-image pandas opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import glob\n",
        "\n",
        "# --- 1. SET THE CORRECT SOURCE PATH ---\n",
        "# Make sure this path to your dataset folder on Google Drive is correct.\n",
        "gdrive_dataset_path = \"/content/drive/MyDrive/Datasets\" # <-- UPDATE THIS PATH IF NEEDED\n",
        "\n",
        "# --- 2. PERFORM THE COPY TO RAM ---\n",
        "print(f\"Copying dataset from '{gdrive_dataset_path}' to RAM disk (/dev/shm)...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# MODIFIED: The destination is now the RAM disk\n",
        "local_dataset_path = \"/dev/shm/datasets\"\n",
        "\n",
        "if os.path.exists(gdrive_dataset_path):\n",
        "    !rsync -a --info=progress2 {gdrive_dataset_path} {local_dataset_path}\n",
        "else:\n",
        "    print(f\"âŒ ERROR: Source path not found: {gdrive_dataset_path}\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\nCopy operation finished in {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "# --- 3. VERIFY THE COPY ---\n",
        "print(\"\\nVerifying copied files in RAM...\")\n",
        "local_base = os.path.join(local_dataset_path, os.path.basename(gdrive_dataset_path.rstrip('/')))\n",
        "\n",
        "div2k_path = os.path.join(local_base, 'DIV2K/HR')\n",
        "flickr2k_path = os.path.join(local_base, 'Flickr2K/HR')\n",
        "set14_path = os.path.join(local_base, 'Set14/image_SRF_4')\n",
        "\n",
        "try:\n",
        "    num_div2k = len(glob.glob(os.path.join(div2k_path, '*.png')))\n",
        "    num_flickr2k = len(glob.glob(os.path.join(flickr2k_path, '*.png')))\n",
        "    num_set14 = len(glob.glob(os.path.join(set14_path, '*.png')))\n",
        "\n",
        "    print(f\"âœ… Found {num_div2k} images in DIV2K.\")\n",
        "    print(f\"âœ… Found {num_flickr2k} images in Flickr2K.\")\n",
        "    print(f\"âœ… Found {num_set14} images in Set14.\")\n",
        "\n",
        "    if num_div2k == 0 or num_flickr2k == 0:\n",
        "        print(\"\\nâš ï¸ WARNING: Training dataset appears empty. Check your paths again.\")\n",
        "    else:\n",
        "        print(\"\\nðŸ‘ Verification successful! You can now proceed to training.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ VERIFICATION FAILED: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ALNDuMWtQSS",
        "outputId": "6268782b-bb4d-4c05-c529-c63fbe87b2e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying dataset from '/content/drive/MyDrive/Datasets' to RAM disk (/dev/shm)...\n",
            "              0 100%    0.00kB/s    0:00:00 (xfr#0, to-chk=0/1)\n",
            "\n",
            "Copy operation finished in 0.49 seconds.\n",
            "\n",
            "Verifying copied files in RAM...\n",
            "âœ… Found 800 images in DIV2K.\n",
            "âœ… Found 2650 images in Flickr2K.\n",
            "âœ… Found 28 images in Set14.\n",
            "\n",
            "ðŸ‘ Verification successful! You can now proceed to training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS97dw5fRaoK"
      },
      "source": [
        "## Cell 2: Project Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyMu0iehRbkf",
        "outputId": "6305c4a9-d793-4064-845e-c4abf33c2a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project directory (on Drive): /content/drive/MyDrive/FusionSR_ClassicalSR_v5\n",
            "Dataset path (in RAM): /dev/shm/datasets/Datasets/\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "class Config:\n",
        "    # --- Project and Directory Paths (Version 5) ---\n",
        "    DRIVE_PREFIX = '/content/drive/MyDrive/'\n",
        "    PROJECT_DIR = os.path.join(DRIVE_PREFIX, 'FusionSR_ClassicalSR_v5')\n",
        "    CHECKPOINTS_DIR = os.path.join(PROJECT_DIR, 'checkpoints')\n",
        "    BEST_MODEL_DIR = os.path.join(PROJECT_DIR, 'best_models')\n",
        "\n",
        "    # --- Dataset Paths ---\n",
        "    # Using local copy in RAM for max speed\n",
        "    LOCAL_DATASET_BASE = '/dev/shm/datasets/Datasets/'\n",
        "    TRAIN_HR_DIR_DIV2K = os.path.join(LOCAL_DATASET_BASE, 'DIV2K/HR')\n",
        "    TRAIN_HR_DIR_FLICKR = os.path.join(LOCAL_DATASET_BASE, 'Flickr2K/HR')\n",
        "    VAL_HR_DIR = os.path.join(LOCAL_DATASET_BASE, 'Set14/image_SRF_4')\n",
        "\n",
        "    # --- Model Architecture ---\n",
        "    UPSCALE_FACTOR = 4\n",
        "    BASE_DIM = 180\n",
        "    NUM_BLOCKS = 8\n",
        "    NUM_HEADS = 6\n",
        "    WINDOW_SIZE = 8\n",
        "\n",
        "    # --- Training Hyperparameters (MODIFIED) ---\n",
        "    NUM_EPOCHS = 50\n",
        "    BATCH_SIZE = 96  # REVERTED: Back to original large batch size\n",
        "    LEARNING_RATE = 2e-4\n",
        "    VGG_LOSS_WEIGHT = 0.1\n",
        "    HR_PATCH_SIZE = 256\n",
        "    GRADIENT_CLIP_VAL = 1.0\n",
        "\n",
        "    # --- Data Loading ---\n",
        "    NUM_WORKERS = 2 # Keeping this at a safe, static number\n",
        "\n",
        "# Create project directories for v5\n",
        "os.makedirs(Config.CHECKPOINTS_DIR, exist_ok=True)\n",
        "os.makedirs(Config.BEST_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# Set up device\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "print(f\"Project directory (on Drive): {Config.PROJECT_DIR}\")\n",
        "print(f\"Dataset path (in RAM): {Config.LOCAL_DATASET_BASE}\")\n",
        "print(f\"Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmVhmfoNRd7e"
      },
      "source": [
        "## Cell 3: Data Pipeline (for Classical SR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k22x3xtCRelE"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "class ClassicalSRDataset(Dataset):\n",
        "    def __init__(self, hr_dirs, hr_patch_size, is_train=True):\n",
        "        super(ClassicalSRDataset, self).__init__()\n",
        "        self.hr_paths = []\n",
        "        for d in hr_dirs:\n",
        "            # Handle both DIV2K and Set14/other naming patterns\n",
        "            self.hr_paths.extend(glob.glob(os.path.join(d, '*.png')))\n",
        "            self.hr_paths.extend(glob.glob(os.path.join(d, '*_HR.png')))\n",
        "\n",
        "        self.hr_patch_size = hr_patch_size\n",
        "        self.is_train = is_train\n",
        "\n",
        "        # Define the transformations\n",
        "        self.hr_crop = transforms.RandomCrop(self.hr_patch_size) if is_train else transforms.CenterCrop(self.hr_patch_size)\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hr_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        hr_image = Image.open(self.hr_paths[idx]).convert('RGB')\n",
        "        hr_patch = self.hr_crop(hr_image)\n",
        "\n",
        "        # ADDED: Data Augmentation for training\n",
        "        if self.is_train:\n",
        "            if random.random() > 0.5: # Random horizontal flip\n",
        "                hr_patch = hr_patch.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "            if random.random() > 0.5: # Random vertical flip\n",
        "                hr_patch = hr_patch.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "            if random.random() > 0.5: # Random 90-degree rotation\n",
        "                hr_patch = hr_patch.rotate(90)\n",
        "\n",
        "        return self.to_tensor(hr_patch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEEZhO5QRgEr"
      },
      "source": [
        "## Cell 4: ðŸ—ï¸ FusionSR Model Architecture (Complete)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "l6OFX205Rgt6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange\n",
        "from torchvision import models\n",
        "\n",
        "# --- Helper Modules ---\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv2d(features, features, kernel_size=3, padding=1), nn.GELU(),\n",
        "            nn.Conv2d(features, features, kernel_size=3, padding=1),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)\n",
        "\n",
        "def window_partition(x, window_size):\n",
        "    B, H, W, C = x.shape\n",
        "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
        "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
        "    return windows\n",
        "\n",
        "def window_reverse(windows, window_size, H, W):\n",
        "    B = int(windows.shape[0] / (H * W / window_size / window_size))\n",
        "    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n",
        "    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n",
        "    return x\n",
        "\n",
        "# --- Core SwinIR-style Components ---\n",
        "class WindowAttention(nn.Module):\n",
        "    def __init__(self, dim, num_heads, window_size):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = dim // num_heads\n",
        "        self.scale = self.head_dim ** -0.5\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=True)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "\n",
        "        # RE-ENABLED: Relative Position Bias\n",
        "        self.relative_position_bias_table = nn.Parameter(\n",
        "            torch.zeros((2 * window_size - 1) * (2 * window_size - 1), num_heads))\n",
        "        coords_h = torch.arange(window_size)\n",
        "        coords_w = torch.arange(window_size)\n",
        "        coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing='ij'))\n",
        "        coords_flatten = torch.flatten(coords, 1)\n",
        "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
        "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
        "        relative_coords[:, :, 0] += window_size - 1\n",
        "        relative_coords[:, :, 1] += window_size - 1\n",
        "        relative_coords[:, :, 0] *= 2 * window_size - 1\n",
        "        relative_position_index = relative_coords.sum(-1)\n",
        "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
        "        nn.init.trunc_normal_(self.relative_position_bias_table, std=.02)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        B_, N, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv.unbind(0)\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "\n",
        "        # RE-ENABLED: Add relative position bias\n",
        "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
        "            N, N, -1).permute(2, 0, 1).contiguous()\n",
        "        attn = attn + relative_position_bias.unsqueeze(0)\n",
        "\n",
        "        if mask is not None:\n",
        "            nW = mask.shape[0]\n",
        "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
        "            attn = attn.view(-1, self.num_heads, N, N)\n",
        "\n",
        "        attn = F.softmax(attn, dim=-1)\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
        "        return self.proj(x)\n",
        "\n",
        "# The rest of this cell (SwinBlock, FusionSR, etc.) is the same as the v4 cell you already have.\n",
        "# I've included it here for completeness.\n",
        "class SwinBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, window_size, shift_size=0):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = WindowAttention(dim, num_heads, window_size)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.mlp = nn.Sequential(nn.Linear(dim, dim * 4), nn.GELU(), nn.Linear(dim * 4, dim))\n",
        "        self.window_size = window_size\n",
        "        self.shift_size = shift_size\n",
        "    def forward(self, x, H, W):\n",
        "        B, L, C = x.shape; shortcut = x; x = self.norm1(x); x = x.view(B, H, W, C)\n",
        "        if self.shift_size > 0: shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
        "        else: shifted_x = x\n",
        "        x_windows = window_partition(shifted_x, self.window_size); x_windows = x_windows.view(-1, self.window_size * self.window_size, C)\n",
        "        attn_mask = None\n",
        "        if self.shift_size > 0:\n",
        "            img_mask = torch.zeros((1, H, W, 1), device=x.device); h_slices = (slice(0, -self.window_size), slice(-self.window_size, -self.shift_size), slice(-self.shift_size, None)); w_slices = (slice(0, -self.window_size), slice(-self.window_size, -self.shift_size), slice(-self.shift_size, None)); cnt = 0\n",
        "            for h in h_slices:\n",
        "                for w in w_slices: img_mask[:, h, w, :] = cnt; cnt += 1\n",
        "            mask_windows = window_partition(img_mask, self.window_size); mask_windows = mask_windows.view(-1, self.window_size * self.window_size); attn_mask = mask_windows.unsqueeze(1) - mask_windows.unsqueeze(2); attn_mask = attn_mask.masked_fill(attn_mask != 0, float(-100.0)).masked_fill(attn_mask == 0, float(0.0))\n",
        "        attn_windows = self.attn(x_windows, mask=attn_mask); shifted_x = window_reverse(attn_windows, self.window_size, H, W)\n",
        "        if self.shift_size > 0: x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n",
        "        else: x = shifted_x\n",
        "        x = x.view(B, L, C); x = shortcut + x; x = x + self.mlp(self.norm2(x)); return x\n",
        "class FusionSR(nn.Module):\n",
        "    def __init__(self, Cfg):\n",
        "        super().__init__(); self.conv_first = nn.Sequential(nn.Conv2d(3, Cfg.BASE_DIM // 2, 3, 1, 1), nn.GELU(), ResidualBlock(Cfg.BASE_DIM // 2), ResidualBlock(Cfg.BASE_DIM // 2), nn.Conv2d(Cfg.BASE_DIM // 2, Cfg.BASE_DIM, 1, 1, 0)); self.body = nn.ModuleList([SwinBlock(dim=Cfg.BASE_DIM, num_heads=Cfg.NUM_HEADS, window_size=Cfg.WINDOW_SIZE, shift_size=0 if (i % 2 == 0) else Cfg.WINDOW_SIZE // 2) for i in range(Cfg.NUM_BLOCKS)]); self.feature_fusion = nn.Sequential(nn.Conv2d(Cfg.BASE_DIM * 2, Cfg.BASE_DIM, 1, 1, 0), nn.GELU(), nn.Conv2d(Cfg.BASE_DIM, Cfg.BASE_DIM, 3, 1, 1)); self.upsample = nn.Sequential(nn.Conv2d(Cfg.BASE_DIM, 3 * (Cfg.UPSCALE_FACTOR ** 2), 3, 1, 1), nn.PixelShuffle(Cfg.UPSCALE_FACTOR))\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape; shallow_features = self.conv_first(x); deep_features_in = rearrange(shallow_features, 'b c h w -> b (h w) c');\n",
        "        for block in self.body: deep_features_in = block(deep_features_in, H, W)\n",
        "        deep_features = rearrange(deep_features_in, 'b (h w) c -> b c h w', h=H, w=W); fused_features = self.feature_fusion(torch.cat((shallow_features, deep_features), dim=1)); return self.upsample(fused_features)\n",
        "class VGGPerceptualLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGGPerceptualLoss, self).__init__(); vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1).features[:36].eval().to(DEVICE);\n",
        "        for param in vgg.parameters(): param.requires_grad = False\n",
        "        self.vgg = vgg; self.loss = nn.L1Loss()\n",
        "    def forward(self, x, y): return self.loss(self.vgg(x), self.vgg(y))\n",
        "class CharbonnierLoss(nn.Module):\n",
        "    def __init__(self, eps=1e-3): super(CharbonnierLoss, self).__init__(); self.eps = eps\n",
        "    def forward(self, x, y): diff = x - y; loss = torch.mean(torch.sqrt(diff * diff + self.eps**2)); return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LTKRomPbzRzp"
      },
      "outputs": [],
      "source": [
        "# !pip install -q torch-ema\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQLbz25uRidl"
      },
      "source": [
        "## Cell 5: ðŸš€ Model Training (Corrected and Complete)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AbrZfe0vRjK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c87a9a24-2d8f-466d-b6b5-45378d4bf79a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Found existing model. Loading weights from: /content/drive/MyDrive/FusionSR_ClassicalSR_v5/best_models/fusionsr_classical_best_v5.pth\n",
            "Resuming training...\n",
            "--- Starting training cycle (Total Epochs: 50) ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [09:24<00:00, 15.68s/it, Loss=0.0881, Pix=0.0793]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Val PSNR: 19.0733 | Val SSIM: 0.3679 | LR: 2.0e-04\n",
            "âœ… New best model saved with PSNR: 19.0733\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:46<00:00,  6.30s/it, Loss=0.0813, Pix=0.0721]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 | Val PSNR: 19.9845 | Val SSIM: 0.4954 | LR: 2.0e-04\n",
            "âœ… New best model saved with PSNR: 19.9845\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:44<00:00,  6.23s/it, Loss=0.0767, Pix=0.0683]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 | Val PSNR: 20.9168 | Val SSIM: 0.5209 | LR: 2.0e-04\n",
            "âœ… New best model saved with PSNR: 20.9168\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:34<00:00,  5.96s/it, Loss=0.0800, Pix=0.0711]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 | Val PSNR: 20.2046 | Val SSIM: 0.3541 | LR: 2.0e-04\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:37<00:00,  6.05s/it, Loss=0.0694, Pix=0.0607]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 | Val PSNR: 21.6787 | Val SSIM: 0.5973 | LR: 2.0e-04\n",
            "âœ… New best model saved with PSNR: 21.6787\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:47<00:00,  6.32s/it, Loss=0.0603, Pix=0.0528]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 | Val PSNR: 22.1951 | Val SSIM: 0.5430 | LR: 1.9e-04\n",
            "âœ… New best model saved with PSNR: 22.1951\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:41<00:00,  6.16s/it, Loss=0.0596, Pix=0.0520]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 | Val PSNR: 22.1651 | Val SSIM: 0.5805 | LR: 1.9e-04\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:50<00:00,  6.41s/it, Loss=0.0619, Pix=0.0539]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 | Val PSNR: 22.6605 | Val SSIM: 0.5240 | LR: 1.9e-04\n",
            "âœ… New best model saved with PSNR: 22.6605\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:54<00:00,  6.52s/it, Loss=0.0573, Pix=0.0496]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 | Val PSNR: 23.2008 | Val SSIM: 0.6129 | LR: 1.8e-04\n",
            "âœ… New best model saved with PSNR: 23.2008\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:47<00:00,  6.33s/it, Loss=0.0560, Pix=0.0482]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 | Val PSNR: 23.1786 | Val SSIM: 0.5112 | LR: 1.8e-04\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:51<00:00,  6.44s/it, Loss=0.0502, Pix=0.0432]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 | Val PSNR: 23.4524 | Val SSIM: 0.5513 | LR: 1.8e-04\n",
            "âœ… New best model saved with PSNR: 23.4524\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:53<00:00,  6.50s/it, Loss=0.0473, Pix=0.0404]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 | Val PSNR: 23.9029 | Val SSIM: 0.6705 | LR: 1.7e-04\n",
            "âœ… New best model saved with PSNR: 23.9029\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:52<00:00,  6.47s/it, Loss=0.0452, Pix=0.0382]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 | Val PSNR: 24.1628 | Val SSIM: 0.7107 | LR: 1.7e-04\n",
            "âœ… New best model saved with PSNR: 24.1628\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:51<00:00,  6.42s/it, Loss=0.0479, Pix=0.0410]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 | Val PSNR: 24.2125 | Val SSIM: 0.6480 | LR: 1.6e-04\n",
            "âœ… New best model saved with PSNR: 24.2125\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:53<00:00,  6.48s/it, Loss=0.0497, Pix=0.0422]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 | Val PSNR: 23.7409 | Val SSIM: 0.5584 | LR: 1.6e-04\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:48<00:00,  6.34s/it, Loss=0.0668, Pix=0.0598]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 | Val PSNR: 23.0998 | Val SSIM: 0.4846 | LR: 1.5e-04\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:58<00:00,  6.63s/it, Loss=0.0538, Pix=0.0473]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 | Val PSNR: 24.0876 | Val SSIM: 0.6152 | LR: 1.5e-04\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:54<00:00,  6.50s/it, Loss=0.0467, Pix=0.0396]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 | Val PSNR: 24.5718 | Val SSIM: 0.7264 | LR: 1.4e-04\n",
            "âœ… New best model saved with PSNR: 24.5718\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:59<00:00,  6.66s/it, Loss=0.0405, Pix=0.0335]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 | Val PSNR: 24.6300 | Val SSIM: 0.7073 | LR: 1.4e-04\n",
            "âœ… New best model saved with PSNR: 24.6300\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:51<00:00,  6.42s/it, Loss=0.0404, Pix=0.0336]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 | Val PSNR: 24.6955 | Val SSIM: 0.6620 | LR: 1.3e-04\n",
            "âœ… New best model saved with PSNR: 24.6955\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:57<00:00,  6.59s/it, Loss=0.0413, Pix=0.0344]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 | Val PSNR: 24.8489 | Val SSIM: 0.7425 | LR: 1.3e-04\n",
            "âœ… New best model saved with PSNR: 24.8489\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:58<00:00,  6.64s/it, Loss=0.0434, Pix=0.0372]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 | Val PSNR: 24.8435 | Val SSIM: 0.7373 | LR: 1.2e-04\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:50<00:00,  6.40s/it, Loss=0.0391, Pix=0.0325]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 | Val PSNR: 24.9184 | Val SSIM: 0.7206 | LR: 1.1e-04\n",
            "âœ… New best model saved with PSNR: 24.9184\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:51<00:00,  6.43s/it, Loss=0.0429, Pix=0.0364]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 | Val PSNR: 25.0268 | Val SSIM: 0.7335 | LR: 1.1e-04\n",
            "âœ… New best model saved with PSNR: 25.0268\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:50<00:00,  6.40s/it, Loss=0.0388, Pix=0.0327]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 | Val PSNR: 25.0176 | Val SSIM: 0.6972 | LR: 1.0e-04\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [04:01<00:00,  6.70s/it, Loss=0.0392, Pix=0.0328]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 | Val PSNR: 25.0786 | Val SSIM: 0.7438 | LR: 9.4e-05\n",
            "âœ… New best model saved with PSNR: 25.0786\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:47<00:00,  6.32s/it, Loss=0.0424, Pix=0.0363]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 | Val PSNR: 24.9408 | Val SSIM: 0.7426 | LR: 8.8e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:46<00:00,  6.29s/it, Loss=0.0428, Pix=0.0363]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 | Val PSNR: 25.0334 | Val SSIM: 0.7430 | LR: 8.2e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:50<00:00,  6.41s/it, Loss=0.0403, Pix=0.0334]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 | Val PSNR: 25.1534 | Val SSIM: 0.7508 | LR: 7.6e-05\n",
            "âœ… New best model saved with PSNR: 25.1534\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:43<00:00,  6.21s/it, Loss=0.0422, Pix=0.0358]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 | Val PSNR: 25.1381 | Val SSIM: 0.7199 | LR: 7.0e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:51<00:00,  6.43s/it, Loss=0.0405, Pix=0.0341]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 | Val PSNR: 25.1678 | Val SSIM: 0.7131 | LR: 6.4e-05\n",
            "âœ… New best model saved with PSNR: 25.1678\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:45<00:00,  6.26s/it, Loss=0.0424, Pix=0.0357]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 | Val PSNR: 25.2053 | Val SSIM: 0.7324 | LR: 5.8e-05\n",
            "âœ… New best model saved with PSNR: 25.2053\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:52<00:00,  6.45s/it, Loss=0.0398, Pix=0.0333]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 | Val PSNR: 25.2373 | Val SSIM: 0.7505 | LR: 5.3e-05\n",
            "âœ… New best model saved with PSNR: 25.2373\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:52<00:00,  6.45s/it, Loss=0.0387, Pix=0.0322]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 | Val PSNR: 25.2491 | Val SSIM: 0.7506 | LR: 4.7e-05\n",
            "âœ… New best model saved with PSNR: 25.2491\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:58<00:00,  6.63s/it, Loss=0.0382, Pix=0.0318]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 | Val PSNR: 25.2411 | Val SSIM: 0.7241 | LR: 4.2e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:50<00:00,  6.40s/it, Loss=0.0380, Pix=0.0316]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 | Val PSNR: 25.2653 | Val SSIM: 0.7538 | LR: 3.7e-05\n",
            "âœ… New best model saved with PSNR: 25.2653\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:53<00:00,  6.48s/it, Loss=0.0407, Pix=0.0340]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 | Val PSNR: 25.2772 | Val SSIM: 0.7447 | LR: 3.2e-05\n",
            "âœ… New best model saved with PSNR: 25.2772\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [04:02<00:00,  6.74s/it, Loss=0.0363, Pix=0.0300]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 | Val PSNR: 25.2861 | Val SSIM: 0.7540 | LR: 2.8e-05\n",
            "âœ… New best model saved with PSNR: 25.2861\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:45<00:00,  6.28s/it, Loss=0.0404, Pix=0.0342]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 | Val PSNR: 25.3008 | Val SSIM: 0.7557 | LR: 2.4e-05\n",
            "âœ… New best model saved with PSNR: 25.3008\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:50<00:00,  6.39s/it, Loss=0.0332, Pix=0.0268]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 | Val PSNR: 25.2977 | Val SSIM: 0.7518 | LR: 2.0e-05\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:47<00:00,  6.32s/it, Loss=0.0375, Pix=0.0309]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 | Val PSNR: 25.3111 | Val SSIM: 0.7530 | LR: 1.6e-05\n",
            "âœ… New best model saved with PSNR: 25.3111\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:53<00:00,  6.50s/it, Loss=0.0431, Pix=0.0361]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 | Val PSNR: 25.3165 | Val SSIM: 0.7550 | LR: 1.3e-05\n",
            "âœ… New best model saved with PSNR: 25.3165\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:50<00:00,  6.40s/it, Loss=0.0365, Pix=0.0306]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 | Val PSNR: 25.3185 | Val SSIM: 0.7540 | LR: 1.0e-05\n",
            "âœ… New best model saved with PSNR: 25.3185\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:45<00:00,  6.25s/it, Loss=0.0415, Pix=0.0353]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 | Val PSNR: 25.3223 | Val SSIM: 0.7541 | LR: 8.0e-06\n",
            "âœ… New best model saved with PSNR: 25.3223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:47<00:00,  6.32s/it, Loss=0.0349, Pix=0.0291]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 | Val PSNR: 25.3273 | Val SSIM: 0.7545 | LR: 5.9e-06\n",
            "âœ… New best model saved with PSNR: 25.3273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:48<00:00,  6.35s/it, Loss=0.0366, Pix=0.0300]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46 | Val PSNR: 25.3299 | Val SSIM: 0.7539 | LR: 4.1e-06\n",
            "âœ… New best model saved with PSNR: 25.3299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:54<00:00,  6.52s/it, Loss=0.0349, Pix=0.0284]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 | Val PSNR: 25.3295 | Val SSIM: 0.7535 | LR: 2.8e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:44<00:00,  6.25s/it, Loss=0.0405, Pix=0.0337]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 | Val PSNR: 25.3303 | Val SSIM: 0.7509 | LR: 1.8e-06\n",
            "âœ… New best model saved with PSNR: 25.3303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:46<00:00,  6.29s/it, Loss=0.0367, Pix=0.0297]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 | Val PSNR: 25.3352 | Val SSIM: 0.7546 | LR: 1.2e-06\n",
            "âœ… New best model saved with PSNR: 25.3352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [03:42<00:00,  6.18s/it, Loss=0.0411, Pix=0.0341]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 | Val PSNR: 25.3351 | Val SSIM: 0.7540 | LR: 1.0e-06\n",
            "--- Training Finished ---\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch.amp import GradScaler, autocast\n",
        "from tqdm import tqdm\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "import numpy as np\n",
        "\n",
        "def train_model():\n",
        "    # --- Dataloaders ---\n",
        "    train_dirs = [Config.TRAIN_HR_DIR_DIV2K, Config.TRAIN_HR_DIR_FLICKR]\n",
        "    train_dataset = ClassicalSRDataset(hr_dirs=train_dirs, hr_patch_size=Config.HR_PATCH_SIZE, is_train=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=Config.NUM_WORKERS, pin_memory=True)\n",
        "    val_dataset = ClassicalSRDataset(hr_dirs=[Config.VAL_HR_DIR], hr_patch_size=Config.HR_PATCH_SIZE, is_train=False)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, pin_memory=True)\n",
        "    gpu_downsampler = transforms.Resize(size=Config.HR_PATCH_SIZE // Config.UPSCALE_FACTOR, interpolation=transforms.InterpolationMode.BICUBIC, antialias=True).to(DEVICE)\n",
        "\n",
        "    # --- Model, Optimizer, Loss ---\n",
        "    model = FusionSR(Config).to(DEVICE)\n",
        "    model = torch.compile(model)\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=Config.LEARNING_RATE, betas=(0.9, 0.99))\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.NUM_EPOCHS, eta_min=1e-6)\n",
        "    criterion_pix = CharbonnierLoss().to(DEVICE)\n",
        "    criterion_vgg = VGGPerceptualLoss().to(DEVICE)\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    # --- MODIFIED: Checkpoint Logic for v5 ---\n",
        "    start_epoch = 0\n",
        "    best_psnr = 0.0\n",
        "    BEST_MODEL_PATH = os.path.join(Config.BEST_MODEL_DIR, \"fusionsr_classical_best_v5.pth\")\n",
        "\n",
        "    # Re-enabled logic to load the best model if it exists\n",
        "    if os.path.exists(BEST_MODEL_PATH):\n",
        "        print(f\"âœ… Found existing model. Loading weights from: {BEST_MODEL_PATH}\")\n",
        "        # Use ._orig_mod to access the model inside the torch.compile wrapper\n",
        "        model._orig_mod.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
        "        print(\"Resuming training...\")\n",
        "    else:\n",
        "        print(\"Starting training from scratch for v5 model.\")\n",
        "\n",
        "\n",
        "    print(f\"--- Starting training cycle (Total Epochs: {Config.NUM_EPOCHS}) ---\")\n",
        "    for epoch in range(start_epoch, Config.NUM_EPOCHS):\n",
        "        model.train()\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{Config.NUM_EPOCHS}\")\n",
        "\n",
        "        for hr_imgs in progress_bar:\n",
        "            hr_imgs = hr_imgs.to(DEVICE, non_blocking=True)\n",
        "            lr_imgs = gpu_downsampler(hr_imgs)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
        "                sr_imgs = model(lr_imgs)\n",
        "                loss_pix = criterion_pix(sr_imgs, hr_imgs)\n",
        "                loss_vgg = criterion_vgg(sr_imgs, hr_imgs)\n",
        "                loss = loss_pix + Config.VGG_LOSS_WEIGHT * loss_vgg\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), Config.GRADIENT_CLIP_VAL)\n",
        "\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            progress_bar.set_postfix({'Loss': f\"{loss.item():.4f}\", 'Pix': f\"{loss_pix.item():.4f}\"})\n",
        "\n",
        "        # --- Validation ---\n",
        "        model.eval()\n",
        "        current_psnr, current_ssim = 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            for hr_tensor in val_loader:\n",
        "                hr_tensor = hr_tensor.to(DEVICE, non_blocking=True)\n",
        "                lr_tensor = gpu_downsampler(hr_tensor)\n",
        "                with autocast(device_type='cuda', dtype=torch.bfloat16):\n",
        "                    sr_tensor = model(lr_tensor)\n",
        "\n",
        "                sr_tensor = sr_tensor.clamp(0, 1).cpu().float()\n",
        "                sr_np = sr_tensor.squeeze(0).permute(1, 2, 0).numpy()\n",
        "                hr_np = hr_tensor.cpu().squeeze(0).permute(1, 2, 0).numpy()\n",
        "\n",
        "                current_psnr += peak_signal_noise_ratio(hr_np, sr_np, data_range=1.0)\n",
        "                current_ssim += structural_similarity(hr_np, sr_np, channel_axis=2, data_range=1.0)\n",
        "\n",
        "        avg_psnr = current_psnr / len(val_loader)\n",
        "        avg_ssim = current_ssim / len(val_loader)\n",
        "\n",
        "        scheduler.step()\n",
        "        print(f\"Epoch {epoch+1} | Val PSNR: {avg_psnr:.4f} | Val SSIM: {avg_ssim:.4f} | LR: {optimizer.param_groups[0]['lr']:.1e}\")\n",
        "\n",
        "        if avg_psnr > best_psnr:\n",
        "            best_psnr = avg_psnr\n",
        "            torch.save(model._orig_mod.state_dict(), BEST_MODEL_PATH)\n",
        "            print(f\"âœ… New best model saved with PSNR: {best_psnr:.4f}\")\n",
        "\n",
        "    print(\"--- Training Finished ---\")\n",
        "\n",
        "train_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRYC5S70Rkru"
      },
      "source": [
        "## Cell 6: ðŸ“Š Model Benchmarking (Complete)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3CXbvGt5RlVN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "be152144-0179-4c26-ee3c-1fa62ae4d3b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Benchmarks on Best Model ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Benchmarking on Set14:   0%|          | 0/42 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[1, 11, 8, 15, 8, 180]' is invalid for input of size 2025000",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-10-284016865.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# UNCOMMENT THE LINE BELOW TO START BENCHMARKING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mbenchmark_sr_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-10-284016865.py\u001b[0m in \u001b[0;36mbenchmark_sr_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlr_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr_tensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Benchmarking on {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mlr_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0msr_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0msr_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msr_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mhr_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhr_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-5-2768851215.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mshallow_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mdeep_features_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshallow_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b c h w -> b (h w) c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeep_features_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep_features_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mdeep_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep_features_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b (h w) c -> b c h w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mfused_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_fusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshallow_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfused_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVGGPerceptualLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-5-2768851215.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, H, W)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mshifted_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshifts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mshifted_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mx_windows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshifted_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mx_windows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_windows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mattn_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-5-2768851215.py\u001b[0m in \u001b[0;36mwindow_partition\u001b[0;34m(x, window_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwindow_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mwindows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwindows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 11, 8, 15, 8, 180]' is invalid for input of size 2025000"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from skimage.metrics import structural_similarity, peak_signal_noise_ratio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "# Re-define the ClassicalSRDataset here for a self-contained cell\n",
        "class BenchmarkSRDataset(Dataset):\n",
        "    def __init__(self, hr_dirs, upscale_factor=4):\n",
        "        self.hr_paths = []\n",
        "        for d in hr_dirs:\n",
        "            self.hr_paths.extend(glob.glob(os.path.join(d, '*.png')))\n",
        "            self.hr_paths.extend(glob.glob(os.path.join(d, '*_HR.png')))\n",
        "\n",
        "        self.upscale_factor = upscale_factor\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hr_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        hr_image = Image.open(self.hr_paths[idx]).convert('RGB')\n",
        "\n",
        "        w, h = hr_image.size\n",
        "        crop_w = w - (w % self.upscale_factor)\n",
        "        crop_h = h - (h % self.upscale_factor)\n",
        "        hr_image = transforms.functional.center_crop(hr_image, (crop_h, crop_w))\n",
        "\n",
        "        lr_image = hr_image.resize(\n",
        "            (hr_image.width // self.upscale_factor, hr_image.height // self.upscale_factor),\n",
        "            Image.BICUBIC\n",
        "        )\n",
        "        return self.to_tensor(lr_image), self.to_tensor(hr_image)\n",
        "\n",
        "def benchmark_sr_model():\n",
        "    BEST_MODEL_PATH = os.path.join(Config.BEST_MODEL_DIR, \"fusionsr_classical_best_v5.pth\")\n",
        "    if not os.path.exists(BEST_MODEL_PATH):\n",
        "        print(f\"Best model not found at {BEST_MODEL_PATH}. Please train the model first.\")\n",
        "        return\n",
        "\n",
        "    model = FusionSR(Config).to(DEVICE)\n",
        "    model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n",
        "    model.eval()\n",
        "\n",
        "    BENCHMARK_DATASETS = {\n",
        "        \"Set14\": Config.VAL_HR_DIR,\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    print(\"\\n--- Starting Benchmarks on Best Model ---\")\n",
        "\n",
        "    for name, path in BENCHMARK_DATASETS.items():\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"\\nPath not found for {name}: {path}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        dataset = BenchmarkSRDataset(hr_dirs=[path], upscale_factor=Config.UPSCALE_FACTOR)\n",
        "        if len(dataset) == 0:\n",
        "            print(f\"\\nNo images found for {name} at {path}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "        psnr_scores, ssim_scores = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for lr_tensor, hr_tensor in tqdm(loader, desc=f\"Benchmarking on {name}\"):\n",
        "                lr_tensor = lr_tensor.to(DEVICE)\n",
        "                sr_tensor = model(lr_tensor).clamp(0, 1).cpu()\n",
        "                sr_np = sr_tensor.squeeze(0).permute(1, 2, 0).numpy()\n",
        "                hr_np = hr_tensor.squeeze(0).permute(1, 2, 0).numpy()\n",
        "                psnr_scores.append(peak_signal_noise_ratio(hr_np, sr_np, data_range=1.0))\n",
        "                ssim_scores.append(structural_similarity(hr_np, sr_np, multichannel=True, data_range=1.0, channel_axis=2))\n",
        "\n",
        "        results.append({\n",
        "            \"Dataset\": name,\n",
        "            \"PSNR (dB)\": f\"{np.mean(psnr_scores):.2f}\",\n",
        "            \"SSIM\": f\"{np.mean(ssim_scores):.4f}\"\n",
        "        })\n",
        "\n",
        "    if results:\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(\"\\n\\n--- FINAL BENCHMARK RESULTS ---\")\n",
        "        print(results_df.to_string(index=False))\n",
        "    else:\n",
        "        print(\"\\n--- No benchmarks were run. Please check your dataset paths. ---\")\n",
        "\n",
        "# UNCOMMENT THE LINE BELOW TO START BENCHMARKING\n",
        "benchmark_sr_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ueFQbngRm6n"
      },
      "source": [
        "Cell 7: ðŸ–¼ï¸ Inference on Custom Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j4JzciccSZP"
      },
      "source": [
        "## Cell 7: ðŸ–¼ï¸ Inference on Custom Images (Complete)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p042lu3ccTCI"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "\n",
        "def infer_and_show():\n",
        "    BEST_MODEL_PATH = os.path.join(Config.BEST_MODEL_DIR, \"fusionsr_classical_best.pth\")\n",
        "    if not os.path.exists(BEST_MODEL_PATH):\n",
        "        print(f\"Best model not found at {BEST_MODEL_PATH}. Please train first.\")\n",
        "        return\n",
        "\n",
        "    model = FusionSR(Config).to(DEVICE)\n",
        "    model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n",
        "    model.eval()\n",
        "\n",
        "    print(\"Please upload a LOW-RESOLUTION image to upscale:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"\\nNo image uploaded. Aborting.\")\n",
        "        return\n",
        "\n",
        "    file_name = list(uploaded.keys())[0]\n",
        "    lr_img = Image.open(io.BytesIO(uploaded[file_name])).convert('RGB')\n",
        "\n",
        "    lr_tensor = transforms.ToTensor()(lr_img).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        sr_tensor = model(lr_tensor).clamp(0, 1).cpu()\n",
        "\n",
        "    sr_img = transforms.ToPILImage()(sr_tensor.squeeze(0))\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 8))\n",
        "    axes[0].imshow(lr_img); axes[0].set_title(\"Original Low-Resolution\"); axes[0].axis('off')\n",
        "    axes[1].imshow(sr_img); axes[1].set_title(f\"FusionSR Upscaled (x{Config.UPSCALE_FACTOR})\"); axes[1].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    output_filename = f\"upscaled_{file_name}\"\n",
        "    sr_img.save(output_filename)\n",
        "    print(f\"\\nUpscaled image saved as {output_filename}. Downloading now...\")\n",
        "    files.download(output_filename)\n",
        "\n",
        "# UNCOMMENT THE LINE BELOW TO RUN INFERENCE\n",
        "infer_and_show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "NjR1kyDJRYCl",
        "iS97dw5fRaoK",
        "jmVhmfoNRd7e",
        "NEEZhO5QRgEr",
        "4j4JzciccSZP"
      ],
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}